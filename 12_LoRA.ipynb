{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "%pip install trl",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%pip install peft",
   "id": "eab402bcac4cf7b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "# LoRA\n",
    "import torch\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType"
   ],
   "id": "ad72626b8c28cf64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LoRA\n",
    "lora_r: int = 8\n",
    "lora_dropout: float = 0.1\n",
    "lora_alpha: int = 32"
   ],
   "id": "10266d3478e1d753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"sahil2801/CodeAlpaca-20k\", split=\"train\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")"
   ],
   "id": "21627149ae22198e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LoRA\n",
    "target_modules = set()\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        names = name.split('.')\n",
    "        target_modules.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "if \"lm_head\" in target_modules:  # needed for 16-bit\n",
    "    target_modules.remove(\"lm_head\")\n",
    "\n",
    "target_modules = list(target_modules)"
   ],
   "id": "3a44598d9570cbf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=target_modules\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ],
   "id": "d91899ba40eb4288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 체크포인트 설정\n",
    "output_dir = \"./checkpoints/lora-instruction-tuning\"\n",
    "save_strategy = \"epoch\"  # 또는 \"steps\" (500스텝마다 저장 시)\n",
    "\n",
    "sft_args = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    save_strategy=save_strategy,          # 에포크 종료 시 저장\n",
    "    save_total_limit=2,             # 최신 2개 체크포인트 유지\n",
    "    resume_from_checkpoint=True,    # 체크포인트 재개 활성화\n",
    "    # SFT 전용 파라미터\n",
    "    max_seq_length=512,\n",
    "    packing=False\n",
    ")"
   ],
   "id": "5c13af3cb49c14d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        text = f\"### Question: {example['instruction'][i]}\\n ### Answer: {example['output'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ],
   "id": "662b166b592b26e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "response_template = \" ### Answer:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)"
   ],
   "id": "29bb7f27538b2e93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=sft_args,                 # SFTConfig 사용 유지\n",
    "    train_dataset=dataset,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator\n",
    ")\n",
    "\n",
    "# 체크포인트 존재 여부 확인\n",
    "checkpoint_exists = os.path.exists(output_dir) and any(\n",
    "    \"checkpoint\" in folder for folder in os.listdir(output_dir)\n",
    ")\n",
    "\n",
    "# 조건부 학습 재개\n",
    "try:\n",
    "    trainer.train(resume_from_checkpoint=checkpoint_exists)\n",
    "except ValueError as e:\n",
    "    if \"No valid checkpoint\" in str(e):\n",
    "        print(\"체크포인트 없음. 새 학습 시작\")\n",
    "        trainer.train(resume_from_checkpoint=False)"
   ],
   "id": "2c00456544ceb684",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
